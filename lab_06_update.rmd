---
title: "lab_06_update"
author: "Rob Wells/Derek Willis"
date: "2025-10-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Combining and merging tables

## Chapter 17

### Task 1: Load libraries and settings

**Task** Run the following code codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# turn off sci notation
options(scipen=999)
library(tidyverse)
library(lubridate)
library(janitor)
```

Often, as data journalists, we’re looking at data across time or at data stored in multiple tables. And to do that, we need to often need to merge that data together.

Depending on what we have, we may just need to stack data on top of each other to make new data. If we have 2019 data and 2018 data and we want that to be one file, we stack them. If we have a dataset of cows in counties and a dataset of populations in county, we’re going to join those two together on the county – the common element.

### Task 2: Stacking data using bind_rows

We have Maryland county voter registration data from five different elections in five different files. They have the same record layout and the same number of counties (plus Baltimore City).

Because they are in identical file format -- same number of columns and data types - we can combine them into a single dataframe using bind_rows.

```{r}
county_voters_2016 <- read_csv("data/county_voters_2016.csv")
county_voters_2018 <- read_csv("data/county_voters_2018.csv")
county_voters_2020 <- read_csv("data/county_voters_2020.csv")
county_voters_2022 <- read_csv("data/county_voters_2022.csv")
county_voters_2024 <- read_csv("data/county_voters_2024.csv")
```


These datasets have the same number of columns, all with the same names, so if we want to merge them together to compare them over time, we can stack them together using bind_rows. Since we have five dataframes, we’re going to need to pass them as a list, meaning they’ll be enclosed inside the list function.

### Task 3: Using bind_rows

**Task** Combine the five files into a single data frame using the bind_rows() function, along with list(). Add a description of what this code does to your reference notebook.

```{r}
# bind_rows with list
county_voters_combined <- bind_rows(list(county_voters_2016, county_voters_2018, county_voters_2020, county_voters_2022, county_voters_2024))
View(county_voters_combined)
```

There are plenty of uses for bind_rows: any regularly updated data that comes in the same format like crime reports or award recipients or player game statistics. Or election results.

## Joining data

More complicated is when you have two separate tables that are connected by a common element or elements. We perform that using join.

Let’s start by reading in some Maryland 2020 county population data:

### Task 4: Loading population data

**Task** Load the Maryland 2020 county population data


```{r}
    maryland_population <- read_csv('data/maryland_population_2020.csv')
```



One of the columns we have is called county, which is what we have in our county_voters_2024 dataframe.

To put the Maryland population data and voter registration data together, we need to use something called a join.

There are different kinds of joins. It’s better if you think of two tables sitting next to each other.

-   A left_join takes all the records from the left table and only the records that match in the right one.

-   A right_join does the same thing.

-   An inner_join takes only the records where they are equal.

-   A full_join which returns all rows of both, regardless of if there’s a match – but I’ve never once had a use for a full join.

In this case, both of our tables have a column called county that has the same characteristics: values in both look identical, including how they distinguish Baltimore City from Baltimore County. This is important, because joins work on exact matches.

We can do this join multiple ways and get a similar result. We can put the population file on the left and the registration data on the right and use a left join to get them all together. And we use join_by() to join by the correct columns. I’m going to count the rows at the end. The reason I’m doing this is important: 

**Rule 1 in joining data is having an idea of what you are expecting to get.**
So with a left join with population on the left, I have 24 rows, so I expect to get 24 rows when I’m done.

### Task 5: Join population and voter data

**Task** Run the following code to join Maryland population data and the 2020 voter registration data together using the common column county as the key. How many rows are there now? How many *should* there be? 


```{r}
# with nrow included to show row total
maryland_population |> left_join(county_voters_2024, join_by(COUNTY)) |> nrow()
```

Remove the nrow and run it again for yourself. By default, dplyr will do a “natural” join, where it’ll match all the matching columns in both tables. So if we take out the by, it’ll use all the common columns between the tables. That may not be right in every instance but let’s try it. If it works, we should get 24 rows.

And if it works, the resulting dataframe will be 10 columns: 9 from county_voters_2024 and one from maryland_population (the County column will be the matching column).

### Task 6: Looking at Joined Data

**Task** Examine the combined data

```{r}
# without nrow
maryland_population_with_voters<- maryland_population |> left_join(county_voters_2024, join_by(COUNTY))
```



Now, with our joined data, we can answer questions in a more useful way. But joins can do even more than just bring data together; they can include additional data to enable you to ask more sophisticated questions. Right now we have registered voters and total population. But we can do more.

Let’s try adding more Maryland demographic data to the mix. Using a file describing the 18-and-over population (from which eligible voters come) from the state’s data catalog, we can read it into R:

### Task 8: Add the Demographic Data

**Task** Load the Maryland demographic data

```{r}
maryland_demographics <- read_csv('data/maryland_demographics.csv')
```

Again, we can use a left_join to make our demographic data available. This time we’ll need to specify the two fields to join because they do not have identical names. We’ll use COUNTY from our population data and NAME from the demographic data.

**The order matters - the first column is from the dataframe you name first.**

### Task 9: Join demographic data to combined voting/population data

**Task** Join the demographic data to the our combined voting/population data by the COUNTY and NAME columns

```{r}
maryland_population_with_voters_and_demographics <- maryland_population_with_voters |> left_join(maryland_demographics, join_by(COUNTY==NAME))
```

Now we’ve got population data and demographic data by county. That means we can draw from both datasets in asking our questions. For example, we could see the counties with the highest 18+ Black population as a percentage of all population 18 and over and also the percentage of Democrats in that county.

We can get this by using mutate and arrange:

### Task 10: Asking Demographic Questions

**Task** Using mutate, let's find the county with the highest 18+ Black population as a percentage of all population 18 and over and also the percentage of Democrats in that county. 

```{r}
maryland_population_with_voters_and_demographics |>
  mutate(pct_black_18_plus = (pop_black/pop_18_over)*100, pct_dems = (DEM/TOTAL)*100) |> 
  arrange(desc(pct_black_18_plus)) |> 
  select(COUNTY, pct_black_18_plus, pct_dems)
```

If you know Maryland political demographics, this result isn’t too surprising, but Somerset County - the state’s 2nd smallest in terms of population - stands out for its Black population, which is a greater percentage than Baltimore County and Montgomery County.

### Task 11: Fixing Join Problems

Sometimes joins look like they should work but don't. Often this is due to the two columns you're joining on having different data types: joining a <chr> column to a <dbl> column, for example. Let's walk through an example of that using some demographic data by zip code.

**Task** Run the following code to load the Zip Code Tabulation Area data for Maryland. What's the datatype of the ZCTA5N? column? 

```{r}
maryland_zcta <- read_csv('data/maryland_zcta.csv')
glimpse(maryland_zcta)
```

The column we're interested in, ZCTA5N, is a <dbl> column - it's a number. We want it to be a <chr> column - text - so we can use it in joins with our next step in this tutorial.

**Task** Run the following code to change the datatype of ZCTA5N from numeric to character. What's the datatype of ZCTA5N now? 

```{r}
maryland_zcta <- maryland_zcta |> mutate(across(ZCTA5N, as.character))
glimpse(maryland_zcta)
```

Now we can join this dataframe to other zip code data where the zip code column is text, not numbers.

------------------------------------------------------------------------

# Lab 06 Updated


## Getting Started

This lab involves combining and joining data to make it more useful and to ask some questions about it. We'll use some more 911 overdose call data to do this. The first thing we want to do is to combine multiple counties' data into a single dataframe so that we can ask some questions. First, let's combine data from Cecil, Carroll and Allegany counties into a new dataframe.

*Before* you combine them you'll need to clean up some of the column names to make the data easier to work with - make sure you have loaded the library to do that. You also need to make sure that each column has the same name and datatype (you can check the datatypes using `glimpse`). If any of them does not, you need to fix that.

You will find the 911 call data for Allegany, Cecil, and Carroll counties in the data folder.

## Lab Task 1: Load and combine the call data from Allegany, Cecil, and Carroll counties using bind_rows. Call it "combined_911" 
```{r}
library(readr)
allegany_911 <- read_csv("data/allegany_911.csv") |>
 clean_names()
cecil_911 <- read_csv("data/cecil_911.csv") |>
  clean_names()
carroll_911 <- read_csv("data/carroll_911.csv") |>
clean_names()
combined_911 <- bind_rows(list(allegany_911, cecil_911, carroll_911))
```

Next, join demographic data with Baltimore City 911 calls. 

## Lab Task 2: Load the Baltimore City 911 data and the maryland_zcta demographic data from the data folder. Join them based on the zip code. Call the dataframe "baltimore_911_with_demographics"

Remember, the zip codes in both dataframes must be the same datatype (and should be characters). You should start with your Baltimore City 911 dataframe in creating your join.

```{r}
baltimore_911 <- read_csv("data/baltimore_911.csv") |>  
  mutate(across(zip_code, as.character)) |>
clean_names()
  MD_zcta <- read_csv("data/maryland_zcta.csv") |> 
    mutate(across(ZCTA5N, as.character)) |>
  clean_names()
```
  
```{r}
baltimore_911_with_demographics <- baltimore_911 |>
 left_join(MD_zcta, join_by(zip_code==zcta5n)) 
```

## Answer questions

Q1. Let's start with the "combined_911" data from Allegany, Cecil and Carroll counties.

Q1a: Write code to generate a dataframe that shows the total number of calls for each county. 


```{r}
county_calls <- combined_911 |>
  clean_names() |>
  group_by(county) |>
  summarise(total_calls = n()) |>
  arrange(desc(total_calls))
```

Q1b: Write the answer: What's the order of counties from most calls to least?
**Write the answer:**
Carroll County has the most amount of calls with 448 calls, followed by Cecil County with 438 calls, and Allegany County has the least amount of calls with 418 calls.


Q2. Use the "combined_911" data. Write code to do the following:

-- Add a column for the month of each call
-- Show the total number of calls per county and month. 

```{r}
county_month_calls <- combined_911 |>
  clean_names() |>
mutate(month = floor_date(date, "month"))

calls_summary<- combined_911 |>
  group_by(county, date) |>
  summarise(total_calls = n(), .groups = 'drop') |>
  arrange(county, date)
```


Q2a: Are there any outliers or noteworthy results? Describe the general pattern of the results.
**Write answer here:**
I find it interesting that crime almost changes with the seasons. Between November to January there were only 296 calls. When spring comes between the months February to May, there was a total of 440 calls. finally in summer there was a total of 481 calls. I feel as though as the weather warms up people get hot and aggitated more which could lead to more conflict, there is also the factor of more people being outside.
Q2b: Use "combined_911" data and write code to calculate the most calls per county and location. 

```{r}
location_per_county <- combined_911 |>
  clean_names() |>
  group_by(county, location) |>
  summarise(total_calls = n()) |>
  arrange(desc(total_calls))

view(location_per_county)
```

Q2c: Which location had the most calls - where and what is that location?
**Write answer here:**
314 Grove Neck Rd. Earleville, MD in Cecil county has 15 total calls. Carroll County's 10 George St. has the most calls in the county at 7 calls and Allegany County's 19410 Old Dans Rock Rd. has 5 total calls. 


Q3. Now let's use the Baltimore City data, "baltimore_911_with_demographics." 

Write code to filter for calls in zip codes where the percentage of under 18 population is at least 75%.

Next, show the zip code and population and how many calls occurred in each of those zip codes.

```{r}
under_18_calls <- baltimore_911_with_demographics |>
 filter(plt18sp >= 75) |>
  group_by(zip_code, pop100) |>
  summarise(total_calls = n()) |>
  arrange(desc(total_calls))


```


Q3a: Where are those zip codes in the city?
**Write the answer here:**
The zip codes are 21217, 21223, 21202, 21213, 21201, 21216, 21205.
Q4: Continuing with the baltimore_911_with_demographics data. Take the table you just created in Q3 and modify it.

Add a column that calculates the number of calls per 1,000 people for those zip codes. To calculate a per capita rate, you might find this short guide handy: [https://observablehq.com/\@palewire/per-capita-calculator](https://observablehq.com/@palewire/per-capita-calculator){.uri}.

```{r}
under_18_zipcodes <- baltimore_911_with_demographics |>
  filter(plt18sp >= 75) |>
  group_by(zip_code, pop100) |>
  summarise(total_calls = n()) |>
  mutate(calls_per_1000 = (total_calls / pop100) * 1000) |>
  arrange(desc(total_calls))
```


Q4a: Which zip code has the highest rate of calls per 1,000 people? Find the neighborhoods in that zip code that are listed in the data - you can use group_by or distinct to do this. 
```{r}
neighborhoods_21217 <- baltimore_911_with_demographics |>
  filter(zip_code == "21217") |>
  distinct(location) |>
  arrange(location)
```

Do an internet search: What are some of those neighborhoods, and what else can you tell me about the population there?
**Write the answer here:**
21217 has the highest rate of calls per 1,000 with 20.8 calls. Within this zip code there are 408 addresses. This zipcode was very high violent and property crime rates. This zip code is in the 1st percentile in regards to safety meaning 99% of zip codes are safer than this area. The population itself is primarily African American, sitting at 81% of the population. Sadly, this area has dealt with high unemployment and high poverty rates, which most likely contributes to the crime rates in this area. 